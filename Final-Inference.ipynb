{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28560972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T14:56:45.884804Z",
     "iopub.status.busy": "2022-03-10T14:56:45.882710Z",
     "iopub.status.idle": "2022-03-10T14:56:56.733604Z",
     "shell.execute_reply": "2022-03-10T14:56:56.732693Z",
     "shell.execute_reply.started": "2022-03-10T14:53:06.233648Z"
    },
    "papermill": {
     "duration": 10.868719,
     "end_time": "2022-03-10T14:56:56.733813",
     "exception": false,
     "start_time": "2022-03-10T14:56:45.865094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import gc\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from functools import partial\n",
    "from albumentations import (Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, CenterCrop, \n",
    "                            HorizontalFlip, VerticalFlip, Rotate, ShiftScaleRotate, Transpose)\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b421b3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T14:56:56.762908Z",
     "iopub.status.busy": "2022-03-10T14:56:56.762100Z",
     "iopub.status.idle": "2022-03-10T14:56:56.781412Z",
     "shell.execute_reply": "2022-03-10T14:56:56.780039Z",
     "shell.execute_reply.started": "2022-03-10T14:53:17.105619Z"
    },
    "papermill": {
     "duration": 0.036518,
     "end_time": "2022-03-10T14:56:56.781559",
     "exception": false,
     "start_time": "2022-03-10T14:56:56.745041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"../input/pgpdataset2022mar07/dataset/\"\n",
    "image_path = path+\"test/\"\n",
    "\n",
    "IMAGE_SIZE = (512,512)\n",
    "submission_df = pd.read_csv('../input/pgpdataset2022mar07/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7183dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T14:56:56.809781Z",
     "iopub.status.busy": "2022-03-10T14:56:56.807225Z",
     "iopub.status.idle": "2022-03-10T14:56:56.813551Z",
     "shell.execute_reply": "2022-03-10T14:56:56.812947Z",
     "shell.execute_reply.started": "2022-03-10T14:53:19.513415Z"
    },
    "papermill": {
     "duration": 0.021525,
     "end_time": "2022-03-10T14:56:56.813692",
     "exception": false,
     "start_time": "2022-03-10T14:56:56.792167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomResNext(nn.Module):\n",
    "        def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n",
    "            super().__init__()\n",
    "            self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "            n_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(n_features, 7)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.model(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f747f8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T14:56:56.843894Z",
     "iopub.status.busy": "2022-03-10T14:56:56.843098Z",
     "iopub.status.idle": "2022-03-10T14:56:56.847101Z",
     "shell.execute_reply": "2022-03-10T14:56:56.846537Z",
     "shell.execute_reply.started": "2022-03-10T14:53:19.826903Z"
    },
    "papermill": {
     "duration": 0.023106,
     "end_time": "2022-03-10T14:56:56.847276",
     "exception": false,
     "start_time": "2022-03-10T14:56:56.824170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_path_ID'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        image = Image.open(file_name)\n",
    "        image = np.array(image)\n",
    "        if image.shape[-1]>3: image = image[:, :, :-1]\n",
    "        if image.shape[0]==1:\n",
    "            image = np.ones((512, 512, 3))\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a778ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T14:56:56.873099Z",
     "iopub.status.busy": "2022-03-10T14:56:56.872437Z",
     "iopub.status.idle": "2022-03-10T14:56:56.877630Z",
     "shell.execute_reply": "2022-03-10T14:56:56.876693Z",
     "shell.execute_reply.started": "2022-03-10T14:53:20.059533Z"
    },
    "papermill": {
     "duration": 0.020445,
     "end_time": "2022-03-10T14:56:56.877791",
     "exception": false,
     "start_time": "2022-03-10T14:56:56.857346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "used_models_pytorch = {\"resnext\": [f'../input/pgp-training/resnext50_32x4d_fold{fold}_best.pth' for fold in [0,1,2,3,4]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d18c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T14:53:21.096704Z",
     "iopub.status.busy": "2022-03-10T14:53:21.096412Z",
     "iopub.status.idle": "2022-03-10T14:56:12.249675Z",
     "shell.execute_reply": "2022-03-10T14:56:12.248696Z",
     "shell.execute_reply.started": "2022-03-10T14:53:21.096673Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-03-10T14:56:56.888100",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"resnext\" in used_models_pytorch:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def get_transforms():\n",
    "        return Compose([Resize(512, 512),\n",
    "                        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                        ToTensorV2()])\n",
    "\n",
    "    def inference(model, states, test_loader, device):\n",
    "        model.to(device)\n",
    "\n",
    "        probabilities = []\n",
    "        for i, (images) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            avg_preds = []\n",
    "            for state in states:\n",
    "                model.load_state_dict(state['model'])\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_preds = model(images)\n",
    "                avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "            avg_preds = np.mean(avg_preds, axis=0)\n",
    "            probabilities.append(avg_preds)\n",
    "        return np.concatenate(probabilities)\n",
    "    \n",
    "\n",
    "    predictions_resnext = pd.DataFrame(columns={\"image_ID\"})\n",
    "    predictions_resnext[\"image_ID\"] = submission_df[\"image_ID\"].values\n",
    "    predictions_resnext['image_path_ID'] = image_path + predictions_resnext['image_ID'].astype(str)\n",
    "\n",
    "    model = CustomResNext('resnext50_32x4d', pretrained=False)\n",
    "    states = [torch.load(f) for f in used_models_pytorch[\"resnext\"]]\n",
    "\n",
    "    test_dataset = TestDataset(predictions_resnext, transform=get_transforms())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=1, pin_memory=True)\n",
    "    predictions = inference(model, states, test_loader, device)\n",
    "\n",
    "    predictions_resnext['resnext'] = [np.squeeze(p) for p in predictions]\n",
    "    predictions_resnext = predictions_resnext.drop([\"image_path_ID\"], axis=1)\n",
    "    \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        del(model)\n",
    "        del(states)\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548469c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-10T14:56:21.311928Z",
     "iopub.status.busy": "2022-03-10T14:56:21.311266Z",
     "iopub.status.idle": "2022-03-10T14:56:21.333607Z",
     "shell.execute_reply": "2022-03-10T14:56:21.332689Z",
     "shell.execute_reply.started": "2022-03-10T14:56:21.311892Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df[\"label\"] = 0\n",
    "\n",
    "if \"resnext\" in used_models_pytorch:\n",
    "    submission_df = submission_df.merge(predictions_resnext, on=\"image_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37436644",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[\"label\"] = submission_df.apply(lambda row: np.argmax(\n",
    "        [np.sum(e) for e in zip(row[\"resnext\"])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'label': {0: 'Cricket', 1: 'Wrestling', 2: 'Tennis', 3:'Badminton', 4: 'Soccer', 5: 'Swimming', 6: 'Karate'}}\n",
    "submission_df = submission_df.replace(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e62d0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_df[[\"image_ID\",\"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-10T14:56:36.228741",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
